pip install langchain openai faiss-cpu tiktoken

$env:OPENAI_API_KEY="sk-proj-IdKCwLMVsDsegxsZL214llnNhQVoWtubIHkSWCG4vaR4WbUlL0xOlhpTxINHZKfUZLjDFLJSJcT3BlbkFJ3dGc5DyJQ5pNY-GcofuSR-wLSPcBm9CB_doVuSIc4bGIeym6BznSmX4YxB6BEA"

# retrieval_qa.py
from langchain.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA

def build_and_query_index(policy_text: str, query: str):
    # --- 1) write sample policy to file (simulates your company doc)
    with open("company_policy.txt", "w", encoding="utf-8") as f:
        f.write(policy_text)

    # --- 2) load the document
    loader = TextLoader("company_policy.txt", encoding="utf-8")
    docs = loader.load()  # returns a list of Document objects

    # --- 3) split into chunks (adjust chunk_size / overlap for your docs)
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200
    )
    docs = splitter.split_documents(docs)

    # --- 4) create embeddings and a FAISS vectorstore
    embeddings = OpenAIEmbeddings()   # uses OPENAI_API_KEY env var
    vectorstore = FAISS.from_documents(docs, embeddings)

    # Optional: persist index for later reuse
    vectorstore.save_local("faiss_index")

    # --- 5) create an LLM and RetrievalQA chain
    llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.0)
    retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 4})
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",         # "map_reduce" or "refine" are useful for large docs
        retriever=retriever,
        return_source_documents=True
    )

    # --- 6) run the query
    result = qa_chain({"query": query})
    answer = result["result"]
    source_docs = result["source_documents"]

    return answer, source_docs

if __name__ == "__main__":
    # --- Example sample policy text (replace with your real file)
    sample_policy = """
    Company XYZ â€” Refund Policy
    Last updated: March 1, 2025

    Overview:
    We offer a full refund for goods returned within 30 days of purchase,
    provided the product is unused and in its original packaging.

    Eligibility:
    - Must include proof of purchase (receipt or order number).
    - Physical goods only; digital downloads and services are non-refundable,
      except where required by law.

    Non-refundable items:
    - Gift cards, perishable goods, personalized items.

    How to request a refund:
    - Email refunds@companyxyz.com with order number and reason.
    - The company will provide an RMA number and return instructions.

    Processing:
    - Once received, refunds are processed within 7-14 business days.
    - Refunds will be issued to the original payment method.

    Contact:
    Customer Support: +1-800-555-0123
    """

    question = "What is the refund policy?"
    ans, docs = build_and_query_index(sample_policy, question)

    print("=== ANSWER ===")
    print(ans)
    print("\n=== SOURCE CHUNKS ===")
    for i, d in enumerate(docs, start=1):
        # Document.text holds the chunk content
        print(f"\n--- source #{i} ---")
        print(d.page_content[:500])   # print first 500 chars
